# ml

## Terminilogy

- **Machine Learning**: Teaching computers to learn patterns from data without explicit programming
- **Linear Regression**: A method to predict continuous values using a straight line equation
- **Gradient Descent**: An optimization algorithm that finds minimum loss by following the steepest downhill direction
- **Training**: The process of teaching a model by showing it examples and adjusting parameters
- **Model**: The mathematical representation that learns patterns (here: a single linear layer)
- **Parameters**: The learnable values in a model (weights and biases)
- **Loss**: A measure of how wrong the model's predictions are
- **Epoch**: One complete pass through all training data
- **Forward Pass**: Computing predictions through the model
- **Backward Pass**: Computing gradients to know how to improve parameters
- **Optimization**: The process of finding the best parameters to minimize loss
- **Inference/Prediction**: Using a trained model to make predictions on new data

## Training Algorithm Terms

- **Loss Function**: Mathematical function that measures prediction error
- **MSE (Mean Squared Error)**: Loss function that squares the difference between predictions and actual values
- **Optimizer**: Algorithm that updates model parameters to reduce loss
- **SGD (Stochastic Gradient Descent)**: Simple optimizer that updates parameters using gradients
- **Learning Rate**: How much to change parameters each step (0.01 = small, careful steps)
- **Backpropagation**: Algorithm to compute gradients of loss with respect to all parameters
- **Gradients**: Partial derivatives showing how loss changes with parameter changes
- **Zero Gradients**: Clearing old gradient values before computing new ones
- **Step**: The optimizer's update operation (moving parameters in the right direction)

## Workflow

> ML workflow : Train â†’ Save â†’ Load â†’ Predict! ðŸŽ¯

## Regression 

### Regression Analsyis

- Primarily used for forecasting, predicting, and identifying relationships between variables
  
